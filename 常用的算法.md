# 最小二乘法

The least-square method，LSM

目标函数 = Σ（观测值-理论值）^2

解法：代数解法，矩阵解法

### 局限性：

* 需要计算逆矩阵，因此需要对样本数据去除冗余
* 样本特征非常大时（超过1w），求逆耗时过长，甚至不可行。可改用迭代法或者通过主成分分析降维后使用LSM

* 拟合函数需是线性的，非线性函数可通过一些技巧转化为线性

* 当样本量m很少，小于特征数n的时候，拟合方程是欠定的，常用的优化方法都无法去拟合数据；当样本量m等于特征说n的时候，用方程组求解就可以了。当m大于n时，拟合方程是超定的，也就是我们常用与最小二乘法的场景了。

$$$$参考资料：[http://www.cnblogs.com/pinard/p/5976811.html](http://www.cnblogs.com/pinard/p/5976811.html)

# 

# 梯度下降

Gradient Descent

### 梯度：

在微积分里面，对多元函数的参数求∂偏导数，把求得的各个参数的偏导数以向量的形式写出来，就是梯度。

从几何意义上讲，就是函数变化增加最快的地方。或者说，沿着梯度向量的方向，更加容易找到函数的最大值。反过来说，沿着梯度向量相反的方向，梯度减少最快，也就是更加容易找到函数的最小值。

### 梯度上升与梯度下降：

通过梯度下降法来一步步的迭代求解，可以得到最小化的损失函数，和模型参数值。

反过来，如果我们需要求解损失函数的最大值，这时就需要用梯度上升法来迭代了。

梯度下降法和梯度上升法是可以互相转化的。比如我们需要求解损失函数f\(θ\)的最小值，这时我们需要用梯度下降法来迭代求解。但是实际上，我们可以反过来求解损失函数 -f\(θ\)的最大值，这时梯度上升法就派上用场了。

梯度下降不一定能找到全局最优解，有可能是一个局部最优解。

### 概念：

* #### 步长 （learning rate）

  梯度下降迭代的过程中，每一步沿梯度负方向前进的长度

* #### 特征（feature）
* #### 假设函数（hypothesis function）

  用于拟合输入样本，而使用的假设函数

* #### 损失函数（loss function）

  为了评估模型好坏，用损失函数来度量拟合的程度。损失函数极小，意味着拟合程度最好，即模型参数最优。

### 算法调优：

* #### 步长选择

  步长太大，会导致迭代过快，甚至有可能错过最优解；步长太小，迭代速度过慢，耗时长。

  可以设置不同的步长，从大到小，如果损失函数在变小，说明取值有效，否则需要增大步长。

* #### 初始选择

  ```
    初始值不同，获得的最小值也可能不同，因为梯度下降求得的只是局部最小值；（除非损失函数是凸函数）

    需要多次使用不同的初始值进行运算，选择损失函数最小化的初值
  ```
* #### 归一化

  ```
    由于样本不同特征的取值范围不一样，可能导致迭代速度过慢，可以对特征数据归一化。

     （x-期望）/标准差
  ```

### 梯度下降算法大家族：

* #### Batch Gradient Descent 批量梯度下降法 BGD

最常见的形式，更新参数的时候使用所有的样本来进行更新。

* #### Stochastic Gradient Descent 随机梯度下降法 SGD

区别是仅仅选取一个样本j来求梯度。

训练速度快，准确度（由于仅仅用一个样本决定梯度，可能不是最优解），收敛速度慢（迭代方向变化很大，不能很快收敛）

* #### Mini-Batch Gradient Descent 小批量梯度下降法 MBGD

批量和随机算法的折中，对于m个样本，取x个子样本来迭代，1&lt;x&lt;m

# 梯度下降算法与最小二乘比较

梯度下降需要选择步长，最小二乘不需要；

梯度下降是迭代求解，最小二乘是计算解析；

样本量不大，且存在解析解，最小二乘计算速度占优势，

样本量大时，由于最小二乘需要求逆，因此梯度下降更具优势；

# 

# 牛顿法、拟牛顿法：

# 

# 梯度下降算法与牛顿法、拟牛顿法比较：

两者都是迭代求解；

梯度下降法师梯度求解，而牛顿法、拟牛顿法是用二阶的海森矩阵的逆矩阵或伪逆矩阵求解。

相对而言，牛顿法、拟牛顿法收敛更快，但是每次迭代耗时更长。





# 最大熵模型

### 熵

度量了事物的不确定性，越不确定的事物，熵越大。

sklearn中无对应的库

### 优点

* 最大熵统计模型获得的是所有满足约束条件的模型中信息熵极大的模型,作为经典的分类模型时准确率较高。

* 可以灵活地设置约束条件

### 缺点

由于约束函数数量和样本数目有关系，导致迭代过程计算量巨大，实际应用比较难。













