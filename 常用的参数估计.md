常用的参数估计方法：极大似然、最大后验估计、贝叶斯估计、最大熵估计、混合模型估计

上述方法之间呈递进关系。

# 极大似然估计

Maximum Likelihood Estimate，MLE

适用场景：模型已知，参数未知

基本思想：在给定模型的情况下，找到最佳的参数，实现模型对样本最大程度的拟合，即样本集出现的可能性最大

两个重要性质：渐近无偏、渐进一致

# 最大后验估计

Maximum A Posteriori，MAP

### MAP与MLE的比较：

在MLE中，参数θ是一个定值，只是这个值未知。最大似然估计是θ的函数，其求解过程就是找到使得最大似然函数最大的那个参数θ。

而在MAP中，参数θ可以看成一个随机变量，有自己的分布，而这个分布函数，需要通过已有的样本集合X得到，即最大后验估计需要计算的是p\(θ\|X\)

# 贝叶斯估计

### 名词术语：

P\(A\)是A的先验概率或边缘概率。之所以称为"先验"是因为它不考虑任何B方面的因素。

P\(A\|B\)是已知B发生后A的条件概率\(在B发生的情况下A发生的可能性\)，也由于得自B的取值而被称作A的后验概率。

P\(B\|A\)是已知A发生后B的条件概率，也由于得自A的取值而被称作B的后验概率。

P\(B\)是B的先验概率或边缘概率，也作标准化常量（normalized constant）。

### 基本公式：

后验概率 = \(相似度\*先验概率\)/标准化常量



### 交叉检验

重复使用数据，把得到的样本数据进行切分，组合为不同的训练集和测试集，用训练集来训练模型，用测试集来评估模型预测的好坏。在此基础上可以得到多组不同的训练集和测试集，某次训练集中的某样本在下次可能成为测试集中的样本，即所谓“交叉”。

* #### 简单交叉检验
* #### S折交叉检验

S-Folder Cross Validation

S折交叉验证会把样本数据随机的分成S份，每次随机的选择S-1份作为训练集，剩下的1份做测试集。当这一轮完成后，重新随机选择S-1份来训练数据。若干轮（小于S）之后，选择损失函数评估最优的模型和参数。

* #### 留一交叉检验

Leave-one-out Cross Validation

它是第二种情况的特例，此时S等于样本数N，这样对于N个样本，每次选择N-1个样本来训练数据，留一个样本来验证模型预测的好坏。此方法主要用于样本量非常少的情况，比如对于普通适中问题，N小于50时，一般采用留一交叉验证。

* ### 自助法

bootstrapping

有m个样本（m较小），每次在这m个样本中随机采集一个样本，放入训练集，采样完后把样本放回。这样重复采集m次，我们得到m个样本组成的训练集。当然，这m个样本中很有可能有重复的样本数据。同时，用原始的m个样本做测试集。这样接着进行交叉验证。由于我们的训练集有重复数据，这会改变数据的分布，因而训练结果会有估计偏差，因此，此种方法不是很常用，除非数据量真的很少，比如小于20个。

### 

















